{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, roc_curve, roc_auc_score, RocCurveDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import joblib\n",
    "import json\n",
    "import copy\n",
    "import hashlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_folder = \"/root/ml_process_feb23/data/processed/\"\n",
    "\n",
    "df_train = joblib.load(pkl_folder + \"df_train.pkl\")\n",
    "x_train = df_train.drop(['card'], axis = 1)\n",
    "y_train = df_train['card']\n",
    "\n",
    "df_train_rus = joblib.load(pkl_folder + \"df_train_rus.pkl\")\n",
    "x_train_rus = df_train_rus.drop(['card'], axis = 1)\n",
    "y_train_rus = df_train_rus['card']\n",
    "\n",
    "df_train_ros = joblib.load(pkl_folder + \"df_train_ros.pkl\")\n",
    "x_train_ros = df_train_ros.drop(['card'], axis = 1)\n",
    "y_train_ros = df_train_ros['card']\n",
    "\n",
    "df_train_smote = joblib.load(pkl_folder + \"df_train_smote.pkl\")\n",
    "x_train_smote = df_train_smote.drop(['card'], axis = 1)\n",
    "y_train_smote = df_train_smote['card']\n",
    "\n",
    "df_valid = joblib.load(pkl_folder + \"df_valid.pkl\")\n",
    "x_valid = df_valid.drop(['card'], axis = 1)\n",
    "y_valid = df_valid['card']\n",
    "\n",
    "df_test = joblib.load(pkl_folder + \"df_test.pkl\")\n",
    "x_test = df_test.drop(['card'], axis = 1)\n",
    "y_test = df_test['card']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['index', 'reports', 'age', 'share', 'owner', 'selfemp',\n",
       "       'dependents', 'majorcards', 'active', 'income_log',\n",
       "       'expenditure_log', 'months_log', 'age_bin', 'reports_bin',\n",
       "       'dependents_bin', 'active_bin'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances for some binned features and its original value\n",
    "bins = ['age_bin', 'reports_bin', 'dependents_bin', 'active_bin']\n",
    "ori_value = ['age', 'reports', 'dependents', 'active']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the **baseline model**, I will not include the binned feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the independent variables for baseline model\n",
    "x_train_base = x_train.drop(bins, axis = 1)\n",
    "x_train_rus_base = x_train_rus.drop(bins, axis = 1)\n",
    "x_train_ros_base = x_train_ros.drop(bins, axis = 1)\n",
    "x_train_base_smote = x_train_smote.drop(bins, axis = 1)\n",
    "x_valid_base = x_valid.drop(bins, axis = 1)\n",
    "x_test_base = x_test.drop(bins, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the independent variables for alternative model\n",
    "x_train_bin = x_train.drop(ori_value, axis = 1)\n",
    "x_train_rus_bin = x_train_rus.drop(ori_value, axis = 1)\n",
    "x_train_ros_bin = x_train_ros.drop(ori_value, axis = 1)\n",
    "x_train_bin_smote = x_train_smote.drop(ori_value, axis = 1)\n",
    "x_valid_bin = x_valid.drop(ori_value, axis = 1)\n",
    "x_test_bin = x_test.drop(ori_value, axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Log Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stamp():\n",
    "    return datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_log_template():\n",
    "    logger = {\n",
    "        \"model_name\" : [],\n",
    "        \"model_uid\" : [],\n",
    "        \"training_time\" : [],\n",
    "        \"training_date\" : [],\n",
    "        \"performance\" : [],\n",
    "        \"f1_score_avg\" : [],\n",
    "        \"data_configurations\" : [],\n",
    "    }\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_log_updater(current_log, log_path):\n",
    "    current_log = current_log.copy()\n",
    "\n",
    "    try:\n",
    "        with open(log_path, \"r\") as file:\n",
    "            last_log = json.load(file)\n",
    "        file.close()\n",
    "    except FileNotFoundError as ffe:\n",
    "        with open(log_path, \"w\") as file:\n",
    "            file.write(\"[]\")\n",
    "        file.close()\n",
    "        with open(log_path, \"r\") as file:\n",
    "            last_log = json.load(file)\n",
    "        file.close()\n",
    "    \n",
    "    last_log.append(current_log)\n",
    "\n",
    "    with open(log_path, \"w\") as file:\n",
    "        json.dump(last_log, file)\n",
    "        file.close()\n",
    "\n",
    "    return last_log"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_baseline        = LogisticRegression()\n",
    "svm_baseline        = SVC()\n",
    "dct_baseline        = DecisionTreeClassifier()\n",
    "rfc_baseline        = RandomForestClassifier()\n",
    "knn_baseline        = KNeighborsClassifier()\n",
    "xgb_baseline        = XGBClassifier()\n",
    "nb_cat_baseline     = CategoricalNB()\n",
    "nb_gauss_baseline   = GaussianNB()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5b86207399c51f71f4a6f37b6e15eb447a1def4c5b4b45f7ac1063b6bb4c5fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
