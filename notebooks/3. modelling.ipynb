{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, roc_curve, roc_auc_score, RocCurveDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import joblib\n",
    "import json\n",
    "import copy\n",
    "import hashlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_folder = \"/root/ml_process_feb23/data/processed/\"\n",
    "\n",
    "df_train = joblib.load(pkl_folder + \"df_train.pkl\")\n",
    "x_train = df_train.drop(['card'], axis = 1)\n",
    "y_train = df_train['card']\n",
    "\n",
    "df_train_rus = joblib.load(pkl_folder + \"df_train_rus.pkl\")\n",
    "x_train_rus = df_train_rus.drop(['card'], axis = 1)\n",
    "y_train_rus = df_train_rus['card']\n",
    "\n",
    "df_train_ros = joblib.load(pkl_folder + \"df_train_ros.pkl\")\n",
    "x_train_ros = df_train_ros.drop(['card'], axis = 1)\n",
    "y_train_ros = df_train_ros['card']\n",
    "\n",
    "df_train_smote = joblib.load(pkl_folder + \"df_train_smote.pkl\")\n",
    "x_train_smote = df_train_smote.drop(['card'], axis = 1)\n",
    "y_train_smote = df_train_smote['card']\n",
    "\n",
    "df_valid = joblib.load(pkl_folder + \"df_valid.pkl\")\n",
    "x_valid = df_valid.drop(['card'], axis = 1)\n",
    "y_valid = df_valid['card']\n",
    "\n",
    "df_test = joblib.load(pkl_folder + \"df_test.pkl\")\n",
    "x_test = df_test.drop(['card'], axis = 1)\n",
    "y_test = df_test['card']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['index', 'reports', 'age', 'share', 'owner', 'selfemp',\n",
       "       'dependents', 'majorcards', 'active', 'income_log',\n",
       "       'expenditure_log', 'months_log', 'age_bin', 'reports_bin',\n",
       "       'dependents_bin', 'active_bin'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances for some binned features and its original value\n",
    "bins = ['age_bin', 'reports_bin', 'dependents_bin', 'active_bin']\n",
    "ori_value = ['age', 'reports', 'dependents', 'active']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the **baseline model**, I will not include the binned feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the independent variables for baseline model\n",
    "x_train_base = x_train.drop(bins, axis = 1)\n",
    "x_train_rus_base = x_train_rus.drop(bins, axis = 1)\n",
    "x_train_ros_base = x_train_ros.drop(bins, axis = 1)\n",
    "x_train_smote_base = x_train_smote.drop(bins, axis = 1)\n",
    "x_valid_base = x_valid.drop(bins, axis = 1)\n",
    "x_test_base = x_test.drop(bins, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the independent variables for alternative model\n",
    "x_train_bin = x_train.drop(ori_value, axis = 1)\n",
    "x_train_rus_bin = x_train_rus.drop(ori_value, axis = 1)\n",
    "x_train_ros_bin = x_train_ros.drop(ori_value, axis = 1)\n",
    "x_train_smote_bin = x_train_smote.drop(ori_value, axis = 1)\n",
    "x_valid_bin = x_valid.drop(ori_value, axis = 1)\n",
    "x_test_bin = x_test.drop(ori_value, axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Log Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stamp():\n",
    "    return datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_log_template():\n",
    "    logger = {\n",
    "        \"model_name\" : [],\n",
    "        \"model_uid\" : [],\n",
    "        \"training_time\" : [],\n",
    "        \"training_date\" : [],\n",
    "        \"performance\" : [],\n",
    "        \"f1_score_avg\" : [],\n",
    "        \"data_configurations\" : [],\n",
    "    }\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_log_updater(current_log, log_path):\n",
    "    current_log = current_log.copy()\n",
    "\n",
    "    try:\n",
    "        with open(log_path, \"r\") as file:\n",
    "            last_log = json.load(file)\n",
    "        file.close()\n",
    "    except FileNotFoundError as ffe:\n",
    "        with open(log_path, \"w\") as file:\n",
    "            file.write(\"[]\")\n",
    "        file.close()\n",
    "        with open(log_path, \"r\") as file:\n",
    "            last_log = json.load(file)\n",
    "        file.close()\n",
    "    \n",
    "    last_log.append(current_log)\n",
    "\n",
    "    with open(log_path, \"w\") as file:\n",
    "        json.dump(last_log, file)\n",
    "        file.close()\n",
    "\n",
    "    return last_log"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model Object"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create instance for each algorithm function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_baseline        = LogisticRegression()      # Logistic regression\n",
    "svm_baseline        = SVC()                     # Support Vector Machine \n",
    "dct_baseline        = DecisionTreeClassifier()  # Decision tree Classifier\n",
    "rfc_baseline        = RandomForestClassifier()  # Random FOrest Classifier\n",
    "knn_baseline        = KNeighborsClassifier()    # k-Nearest Neighbors CLassifier\n",
    "xgb_baseline        = XGBClassifier()           # XG Boost Classifier\n",
    "nb_cat_baseline     = CategoricalNB()           # Categorical Naive Bayes Classifier\n",
    "nb_gauss_baseline   = GaussianNB()              # Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_model = {\n",
    "    \"imbalanced\" : [\n",
    "        { \"model_name\": lgr_baseline.__class__.__name__, \"model_object\": lgr_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": svm_baseline.__class__.__name__, \"model_object\": dct_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": dct_baseline.__class__.__name__, \"model_object\": dct_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": rfc_baseline.__class__.__name__, \"model_object\": rfc_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": knn_baseline.__class__.__name__, \"model_object\": knn_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": xgb_baseline.__class__.__name__, \"model_object\": xgb_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": nb_cat_baseline.__class__.__name__, \"model_object\": knn_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": nb_gauss_baseline.__class__.__name__, \"model_object\": xgb_baseline, \"model_uid\": \"\"}\n",
    "        ],\n",
    "    \"undersampling\" : [\n",
    "        { \"model_name\": lgr_baseline.__class__.__name__, \"model_object\": lgr_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": svm_baseline.__class__.__name__, \"model_object\": dct_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": dct_baseline.__class__.__name__, \"model_object\": dct_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": rfc_baseline.__class__.__name__, \"model_object\": rfc_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": knn_baseline.__class__.__name__, \"model_object\": knn_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": xgb_baseline.__class__.__name__, \"model_object\": xgb_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": nb_cat_baseline.__class__.__name__, \"model_object\": knn_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": nb_gauss_baseline.__class__.__name__, \"model_object\": xgb_baseline, \"model_uid\": \"\"}\n",
    "        ],\n",
    "    \"oversampling\" : [\n",
    "        { \"model_name\": lgr_baseline.__class__.__name__, \"model_object\": lgr_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": svm_baseline.__class__.__name__, \"model_object\": dct_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": dct_baseline.__class__.__name__, \"model_object\": dct_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": rfc_baseline.__class__.__name__, \"model_object\": rfc_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": knn_baseline.__class__.__name__, \"model_object\": knn_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": xgb_baseline.__class__.__name__, \"model_object\": xgb_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": nb_cat_baseline.__class__.__name__, \"model_object\": knn_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": nb_gauss_baseline.__class__.__name__, \"model_object\": xgb_baseline, \"model_uid\": \"\"}\n",
    "        ],\n",
    "    \"smote\" : [\n",
    "        { \"model_name\": lgr_baseline.__class__.__name__, \"model_object\": lgr_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": svm_baseline.__class__.__name__, \"model_object\": dct_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": dct_baseline.__class__.__name__, \"model_object\": dct_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": rfc_baseline.__class__.__name__, \"model_object\": rfc_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": knn_baseline.__class__.__name__, \"model_object\": knn_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": xgb_baseline.__class__.__name__, \"model_object\": xgb_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": nb_cat_baseline.__class__.__name__, \"model_object\": knn_baseline, \"model_uid\": \"\"},\n",
    "        { \"model_name\": nb_gauss_baseline.__class__.__name__, \"model_object\": xgb_baseline, \"model_uid\": \"\"}\n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_model(list_of_model, prefix_model_name, x_train, y_train, data_configuration_name, x_valid, y_valid, log_path):\n",
    "\n",
    "    list_of_model = copy.deepcopy(list_of_model)\n",
    "    logger = create_log_template()\n",
    "\n",
    "    for model in tqdm(list_of_model):    \n",
    "        model_name = prefix_model_name + \"-\" + model[\"model_name\"]\n",
    "\n",
    "        start_time = time_stamp()\n",
    "        model[\"model_object\"].fit(x_train, y_train)\n",
    "        finished_time = time_stamp()\n",
    "\n",
    "        elapsed_time = finished_time - start_time\n",
    "        elapsed_time = elapsed_time.total_seconds()\n",
    "\n",
    "        y_pred = model[\"model_object\"].predict(x_valid)\n",
    "        performance = classification_report(y_valid, y_pred, output_dict = True)\n",
    "\n",
    "        plain_id = str(start_time) + str(finished_time)\n",
    "        chiper_id = hashlib.md5(plain_id.encode()).hexdigest()\n",
    "\n",
    "        model[\"model_uid\"] = chiper_id\n",
    "\n",
    "        logger[\"model_name\"].append(model_name)\n",
    "        logger[\"model_uid\"].append(chiper_id)\n",
    "        logger[\"training_time\"].append(elapsed_time)\n",
    "        logger[\"training_date\"].append(str(start_time))\n",
    "        logger[\"performance\"].append(performance)\n",
    "        logger[\"f1_score_avg\"].append(performance[\"macro avg\"][\"f1-score\"])\n",
    "        logger[\"data_configurations\"].append(data_configuration_name)\n",
    "\n",
    "    training_log = training_log_updater(logger, log_path)\n",
    "\n",
    "    return training_log, list_of_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Baseline Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original (imbalanced) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/root/ml_process_feb23/venv2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|██████████| 8/8 [00:03<00:00,  2.47it/s]\n"
     ]
    }
   ],
   "source": [
    "training_log, list_of_model_imbal = train_eval_model(\n",
    "    list_of_model[\"imbalanced\"],\n",
    "    \"baseline_model\",\n",
    "    x_train_base,\n",
    "    y_train,\n",
    "    \"imbalanced\",\n",
    "    x_valid_base,\n",
    "    y_valid,\n",
    "    \"/root/ml_process_feb23/docs/training_log_baseline.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_model[\"imbalanced\"] = copy.deepcopy(list_of_model_imbal)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced with undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/root/ml_process_feb23/venv2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|██████████| 8/8 [00:08<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "training_log, list_of_model_rus = train_eval_model(\n",
    "    list_of_model[\"undersampling\"],\n",
    "    \"baseline_model\",\n",
    "    x_train_rus_base,\n",
    "    y_train_rus,\n",
    "    \"undersampling\",\n",
    "    x_valid_base,\n",
    "    y_valid,\n",
    "    \"/root/ml_process_feb23/docs/training_log_baseline.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_model[\"undersampling\"] = copy.deepcopy(list_of_model_rus)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced with oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/root/ml_process_feb23/venv2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|██████████| 8/8 [00:03<00:00,  2.44it/s]\n"
     ]
    }
   ],
   "source": [
    "training_log, list_of_model_ros = train_eval_model(\n",
    "    list_of_model[\"oversampling\"],\n",
    "    \"baseline_model\",\n",
    "    x_train_ros_base,\n",
    "    y_train_ros,\n",
    "    \"oversampling\",\n",
    "    x_valid_base,\n",
    "    y_valid,\n",
    "    \"/root/ml_process_feb23/docs/training_log_baseline.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_model[\"oversampling\"] = copy.deepcopy(list_of_model_ros)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/root/ml_process_feb23/venv2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "training_log, list_of_model_smote = train_eval_model(\n",
    "    list_of_model[\"smote\"],\n",
    "    \"baseline_model\",\n",
    "    x_train_smote_base,\n",
    "    y_train_smote,\n",
    "    \"smote\",\n",
    "    x_valid_base,\n",
    "    y_valid,\n",
    "    \"/root/ml_process_feb23/docs/training_log_baseline.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_model[\"smote\"] = copy.deepcopy(list_of_model_smote)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of models performance\n",
    "\n",
    "Now let's compare the performance from each algorithm and each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_log_to_df(training_log):\n",
    "    training_res = pd.DataFrame()\n",
    "\n",
    "    for log in tqdm(training_log):\n",
    "        training_res = pd.concat([training_res, pd.DataFrame(log)])\n",
    "    \n",
    "    training_res.sort_values([\"f1_score_avg\", \"training_time\"], ascending = [False, True], inplace = True)\n",
    "    training_res.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    return training_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "training_res_baseline = training_log_to_df(training_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_uid</th>\n",
       "      <th>training_time</th>\n",
       "      <th>training_date</th>\n",
       "      <th>performance</th>\n",
       "      <th>f1_score_avg</th>\n",
       "      <th>data_configurations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline_model-RandomForestClassifier</td>\n",
       "      <td>d2024bbbeffaa419c81f9cce722e6aa7</td>\n",
       "      <td>0.658245</td>\n",
       "      <td>2023-03-17 15:21:15.874700</td>\n",
       "      <td>{'0': {'precision': 0.9130434782608695, 'recal...</td>\n",
       "      <td>0.970230</td>\n",
       "      <td>imbalanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline_model-RandomForestClassifier</td>\n",
       "      <td>5372f2a6b2001d82bf17afe009456103</td>\n",
       "      <td>1.436958</td>\n",
       "      <td>2023-03-17 15:24:04.385977</td>\n",
       "      <td>{'0': {'precision': 0.9130434782608695, 'recal...</td>\n",
       "      <td>0.970230</td>\n",
       "      <td>oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline_model-RandomForestClassifier</td>\n",
       "      <td>cdd88d4634a95305eec9cc865bc174bd</td>\n",
       "      <td>0.829285</td>\n",
       "      <td>2023-03-17 15:25:28.425261</td>\n",
       "      <td>{'0': {'precision': 0.8936170212765957, 'recal...</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline_model-GaussianNB</td>\n",
       "      <td>7de58a7cbec49af09fadb50758818fa3</td>\n",
       "      <td>0.972729</td>\n",
       "      <td>2023-03-17 15:25:40.694870</td>\n",
       "      <td>{'0': {'precision': 0.8936170212765957, 'recal...</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline_model-XGBClassifier</td>\n",
       "      <td>bbfe306e6e4a721e0fc616c1c14cff96</td>\n",
       "      <td>1.932120</td>\n",
       "      <td>2023-03-17 15:25:38.627883</td>\n",
       "      <td>{'0': {'precision': 0.8936170212765957, 'recal...</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>baseline_model-CategoricalNB</td>\n",
       "      <td>f3773044516f5f642b942dd6a8cbd8f4</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>2023-03-17 15:25:17.701648</td>\n",
       "      <td>{'0': {'precision': 0.16666666666666666, 'reca...</td>\n",
       "      <td>0.458421</td>\n",
       "      <td>imbalanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>baseline_model-KNeighborsClassifier</td>\n",
       "      <td>4876a41354a278c3f7b704fe9aa085a4</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>2023-03-17 15:25:16.933651</td>\n",
       "      <td>{'0': {'precision': 0.16666666666666666, 'reca...</td>\n",
       "      <td>0.458421</td>\n",
       "      <td>imbalanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>baseline_model-CategoricalNB</td>\n",
       "      <td>48a85f1961b7399ce532498b5f9ea90d</td>\n",
       "      <td>0.009596</td>\n",
       "      <td>2023-03-17 15:21:16.866303</td>\n",
       "      <td>{'0': {'precision': 0.16666666666666666, 'reca...</td>\n",
       "      <td>0.458421</td>\n",
       "      <td>imbalanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>baseline_model-KNeighborsClassifier</td>\n",
       "      <td>99265de149bb849c206b1b5a97a7f9b7</td>\n",
       "      <td>0.011212</td>\n",
       "      <td>2023-03-17 15:21:16.604639</td>\n",
       "      <td>{'0': {'precision': 0.16666666666666666, 'reca...</td>\n",
       "      <td>0.458421</td>\n",
       "      <td>imbalanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>baseline_model-KNeighborsClassifier</td>\n",
       "      <td>761e0108e9de38daa2442af7c78846dd</td>\n",
       "      <td>1.143396</td>\n",
       "      <td>2023-03-17 15:19:02.873770</td>\n",
       "      <td>{'0': {'precision': 0.16666666666666666, 'reca...</td>\n",
       "      <td>0.458421</td>\n",
       "      <td>imbalanced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model_name                         model_uid  \\\n",
       "0   baseline_model-RandomForestClassifier  d2024bbbeffaa419c81f9cce722e6aa7   \n",
       "1   baseline_model-RandomForestClassifier  5372f2a6b2001d82bf17afe009456103   \n",
       "2   baseline_model-RandomForestClassifier  cdd88d4634a95305eec9cc865bc174bd   \n",
       "3               baseline_model-GaussianNB  7de58a7cbec49af09fadb50758818fa3   \n",
       "4            baseline_model-XGBClassifier  bbfe306e6e4a721e0fc616c1c14cff96   \n",
       "..                                    ...                               ...   \n",
       "59           baseline_model-CategoricalNB  f3773044516f5f642b942dd6a8cbd8f4   \n",
       "60    baseline_model-KNeighborsClassifier  4876a41354a278c3f7b704fe9aa085a4   \n",
       "61           baseline_model-CategoricalNB  48a85f1961b7399ce532498b5f9ea90d   \n",
       "62    baseline_model-KNeighborsClassifier  99265de149bb849c206b1b5a97a7f9b7   \n",
       "63    baseline_model-KNeighborsClassifier  761e0108e9de38daa2442af7c78846dd   \n",
       "\n",
       "    training_time               training_date  \\\n",
       "0        0.658245  2023-03-17 15:21:15.874700   \n",
       "1        1.436958  2023-03-17 15:24:04.385977   \n",
       "2        0.829285  2023-03-17 15:25:28.425261   \n",
       "3        0.972729  2023-03-17 15:25:40.694870   \n",
       "4        1.932120  2023-03-17 15:25:38.627883   \n",
       "..            ...                         ...   \n",
       "59       0.005277  2023-03-17 15:25:17.701648   \n",
       "60       0.006233  2023-03-17 15:25:16.933651   \n",
       "61       0.009596  2023-03-17 15:21:16.866303   \n",
       "62       0.011212  2023-03-17 15:21:16.604639   \n",
       "63       1.143396  2023-03-17 15:19:02.873770   \n",
       "\n",
       "                                          performance  f1_score_avg  \\\n",
       "0   {'0': {'precision': 0.9130434782608695, 'recal...      0.970230   \n",
       "1   {'0': {'precision': 0.9130434782608695, 'recal...      0.970230   \n",
       "2   {'0': {'precision': 0.8936170212765957, 'recal...      0.963076   \n",
       "3   {'0': {'precision': 0.8936170212765957, 'recal...      0.963076   \n",
       "4   {'0': {'precision': 0.8936170212765957, 'recal...      0.963076   \n",
       "..                                                ...           ...   \n",
       "59  {'0': {'precision': 0.16666666666666666, 'reca...      0.458421   \n",
       "60  {'0': {'precision': 0.16666666666666666, 'reca...      0.458421   \n",
       "61  {'0': {'precision': 0.16666666666666666, 'reca...      0.458421   \n",
       "62  {'0': {'precision': 0.16666666666666666, 'reca...      0.458421   \n",
       "63  {'0': {'precision': 0.16666666666666666, 'reca...      0.458421   \n",
       "\n",
       "   data_configurations  \n",
       "0           imbalanced  \n",
       "1         oversampling  \n",
       "2         oversampling  \n",
       "3                smote  \n",
       "4                smote  \n",
       "..                 ...  \n",
       "59          imbalanced  \n",
       "60          imbalanced  \n",
       "61          imbalanced  \n",
       "62          imbalanced  \n",
       "63          imbalanced  \n",
       "\n",
       "[64 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_res_baseline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Alternative Models\n",
    "\n",
    "The binned value features are used in the datasets for this model training process. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original (imbalanced) data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/root/ml_process_feb23/venv2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|██████████| 8/8 [00:08<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "training_log, list_of_model_imbal = train_eval_model(\n",
    "    list_of_model[\"imbalanced\"],\n",
    "    \"alternative_model\",\n",
    "    x_train_bin,\n",
    "    y_train,\n",
    "    \"imbalanced\",\n",
    "    x_valid_bin,\n",
    "    y_valid,\n",
    "    \"/root/ml_process_feb23/docs/training_log_alternative.json\"\n",
    ")\n",
    "list_of_model[\"imbalanced\"] = copy.deepcopy(list_of_model_imbal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_model[\"imbalanced\"] = copy.deepcopy(list_of_model_imbal)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced with undersampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/root/ml_process_feb23/venv2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|██████████| 8/8 [00:02<00:00,  3.84it/s]\n"
     ]
    }
   ],
   "source": [
    "training_log, list_of_model_rus = train_eval_model(\n",
    "    list_of_model[\"undersampling\"],\n",
    "    \"alternative_model\",\n",
    "    x_train_rus_bin,\n",
    "    y_train_rus,\n",
    "    \"undersampling\",\n",
    "    x_valid_bin,\n",
    "    y_valid,\n",
    "    \"/root/ml_process_feb23/docs/training_log_alternative.json\"\n",
    ")\n",
    "list_of_model[\"undersampling\"] = copy.deepcopy(list_of_model_rus)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced with oversampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/root/ml_process_feb23/venv2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|██████████| 8/8 [00:01<00:00,  6.74it/s]\n"
     ]
    }
   ],
   "source": [
    "training_log, list_of_model_ros = train_eval_model(\n",
    "    list_of_model[\"oversampling\"],\n",
    "    \"alternative_model\",\n",
    "    x_train_ros_bin,\n",
    "    y_train_ros,\n",
    "    \"oversampling\",\n",
    "    x_valid_bin,\n",
    "    y_valid,\n",
    "    \"/root/ml_process_feb23/docs/training_log_alternative.json\"\n",
    ")\n",
    "list_of_model[\"oversampling\"] = copy.deepcopy(list_of_model_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_model[\"oversampling\"] = copy.deepcopy(list_of_model_ros)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced with SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/root/ml_process_feb23/venv2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.41it/s]\n"
     ]
    }
   ],
   "source": [
    "training_log, list_of_model_smote = train_eval_model(\n",
    "    list_of_model[\"smote\"],\n",
    "    \"alternative_model\",\n",
    "    x_train_smote_bin,\n",
    "    y_train_smote,\n",
    "    \"smote\",\n",
    "    x_valid_bin,\n",
    "    y_valid,\n",
    "    \"/root/ml_process_feb23/docs/training_log_alternative.json\"\n",
    ")\n",
    "list_of_model[\"smote\"] = copy.deepcopy(list_of_model_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_model[\"smote\"] = copy.deepcopy(list_of_model_smote)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of models performance\n",
    "\n",
    "Now let's compare the performance from each algorithm and each dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_log_to_df(training_log):\n",
    "    training_res = pd.DataFrame()\n",
    "\n",
    "    for log in tqdm(training_log):\n",
    "        training_res = pd.concat([training_res, pd.DataFrame(log)])\n",
    "    \n",
    "    training_res.sort_values([\"f1_score_avg\", \"training_time\"], ascending = [False, True], inplace = True)\n",
    "    training_res.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    return training_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 282.21it/s]\n"
     ]
    }
   ],
   "source": [
    "training_res_alternative = training_log_to_df(training_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_uid</th>\n",
       "      <th>training_time</th>\n",
       "      <th>training_date</th>\n",
       "      <th>performance</th>\n",
       "      <th>f1_score_avg</th>\n",
       "      <th>data_configurations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alternative_model-RandomForestClassifier</td>\n",
       "      <td>f630c3a65d06800df553e0ab4c66be13</td>\n",
       "      <td>0.422317</td>\n",
       "      <td>2023-03-17 17:15:33.920571</td>\n",
       "      <td>{'0': {'precision': 0.8936170212765957, 'recal...</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alternative_model-RandomForestClassifier</td>\n",
       "      <td>3f74843f23a8143bc3de556ceddf06d7</td>\n",
       "      <td>0.780525</td>\n",
       "      <td>2023-03-17 17:15:20.401430</td>\n",
       "      <td>{'0': {'precision': 0.8936170212765957, 'recal...</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>imbalanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline_model-SVC</td>\n",
       "      <td>4f375bd57d0d63469f9e6cb60a01341e</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>2023-03-17 17:11:44.744757</td>\n",
       "      <td>{'0': {'precision': 0.875, 'recall': 1.0, 'f1-...</td>\n",
       "      <td>0.956028</td>\n",
       "      <td>undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline_model-DecisionTreeClassifier</td>\n",
       "      <td>8c8ff8cad3f681e6fb97a436f68956c1</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>2023-03-17 17:11:44.781818</td>\n",
       "      <td>{'0': {'precision': 0.875, 'recall': 1.0, 'f1-...</td>\n",
       "      <td>0.956028</td>\n",
       "      <td>undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alternative_model-SVC</td>\n",
       "      <td>81cca94def5b0f6631f5eecc0d05a36d</td>\n",
       "      <td>0.008862</td>\n",
       "      <td>2023-03-17 17:15:31.216044</td>\n",
       "      <td>{'0': {'precision': 0.875, 'recall': 1.0, 'f1-...</td>\n",
       "      <td>0.956028</td>\n",
       "      <td>undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>baseline_model-KNeighborsClassifier</td>\n",
       "      <td>3cd139d9c945cbdbb0975807e7583feb</td>\n",
       "      <td>0.444625</td>\n",
       "      <td>2023-03-17 17:11:33.112479</td>\n",
       "      <td>{'0': {'precision': 1.0, 'recall': 0.142857142...</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>imbalanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>baseline_model-CategoricalNB</td>\n",
       "      <td>01a704b8ce0f3fc85c3fb4a0eef51bd4</td>\n",
       "      <td>0.004445</td>\n",
       "      <td>2023-03-17 17:11:46.500107</td>\n",
       "      <td>{'0': {'precision': 0.25287356321839083, 'reca...</td>\n",
       "      <td>0.495646</td>\n",
       "      <td>undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>alternative_model-CategoricalNB</td>\n",
       "      <td>d24d9dceec958d22af95fab2c4e1e6cd</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>2023-03-17 17:15:32.351095</td>\n",
       "      <td>{'0': {'precision': 0.25287356321839083, 'reca...</td>\n",
       "      <td>0.495646</td>\n",
       "      <td>undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>alternative_model-KNeighborsClassifier</td>\n",
       "      <td>2f6e2ea33f32923a76682b09c8e4f260</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>2023-03-17 17:15:31.960264</td>\n",
       "      <td>{'0': {'precision': 0.25287356321839083, 'reca...</td>\n",
       "      <td>0.495646</td>\n",
       "      <td>undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>baseline_model-KNeighborsClassifier</td>\n",
       "      <td>f81c23a59b6700144106d4735860ffb0</td>\n",
       "      <td>0.008839</td>\n",
       "      <td>2023-03-17 17:11:45.837092</td>\n",
       "      <td>{'0': {'precision': 0.25287356321839083, 'reca...</td>\n",
       "      <td>0.495646</td>\n",
       "      <td>undersampling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  model_name  \\\n",
       "0   alternative_model-RandomForestClassifier   \n",
       "1   alternative_model-RandomForestClassifier   \n",
       "2                         baseline_model-SVC   \n",
       "3      baseline_model-DecisionTreeClassifier   \n",
       "4                      alternative_model-SVC   \n",
       "..                                       ...   \n",
       "59       baseline_model-KNeighborsClassifier   \n",
       "60              baseline_model-CategoricalNB   \n",
       "61           alternative_model-CategoricalNB   \n",
       "62    alternative_model-KNeighborsClassifier   \n",
       "63       baseline_model-KNeighborsClassifier   \n",
       "\n",
       "                           model_uid  training_time  \\\n",
       "0   f630c3a65d06800df553e0ab4c66be13       0.422317   \n",
       "1   3f74843f23a8143bc3de556ceddf06d7       0.780525   \n",
       "2   4f375bd57d0d63469f9e6cb60a01341e       0.005673   \n",
       "3   8c8ff8cad3f681e6fb97a436f68956c1       0.007013   \n",
       "4   81cca94def5b0f6631f5eecc0d05a36d       0.008862   \n",
       "..                               ...            ...   \n",
       "59  3cd139d9c945cbdbb0975807e7583feb       0.444625   \n",
       "60  01a704b8ce0f3fc85c3fb4a0eef51bd4       0.004445   \n",
       "61  d24d9dceec958d22af95fab2c4e1e6cd       0.004584   \n",
       "62  2f6e2ea33f32923a76682b09c8e4f260       0.005389   \n",
       "63  f81c23a59b6700144106d4735860ffb0       0.008839   \n",
       "\n",
       "                 training_date  \\\n",
       "0   2023-03-17 17:15:33.920571   \n",
       "1   2023-03-17 17:15:20.401430   \n",
       "2   2023-03-17 17:11:44.744757   \n",
       "3   2023-03-17 17:11:44.781818   \n",
       "4   2023-03-17 17:15:31.216044   \n",
       "..                         ...   \n",
       "59  2023-03-17 17:11:33.112479   \n",
       "60  2023-03-17 17:11:46.500107   \n",
       "61  2023-03-17 17:15:32.351095   \n",
       "62  2023-03-17 17:15:31.960264   \n",
       "63  2023-03-17 17:11:45.837092   \n",
       "\n",
       "                                          performance  f1_score_avg  \\\n",
       "0   {'0': {'precision': 0.8936170212765957, 'recal...      0.963076   \n",
       "1   {'0': {'precision': 0.8936170212765957, 'recal...      0.963076   \n",
       "2   {'0': {'precision': 0.875, 'recall': 1.0, 'f1-...      0.956028   \n",
       "3   {'0': {'precision': 0.875, 'recall': 1.0, 'f1-...      0.956028   \n",
       "4   {'0': {'precision': 0.875, 'recall': 1.0, 'f1-...      0.956028   \n",
       "..                                                ...           ...   \n",
       "59  {'0': {'precision': 1.0, 'recall': 0.142857142...      0.569444   \n",
       "60  {'0': {'precision': 0.25287356321839083, 'reca...      0.495646   \n",
       "61  {'0': {'precision': 0.25287356321839083, 'reca...      0.495646   \n",
       "62  {'0': {'precision': 0.25287356321839083, 'reca...      0.495646   \n",
       "63  {'0': {'precision': 0.25287356321839083, 'reca...      0.495646   \n",
       "\n",
       "   data_configurations  \n",
       "0         oversampling  \n",
       "1           imbalanced  \n",
       "2        undersampling  \n",
       "3        undersampling  \n",
       "4        undersampling  \n",
       "..                 ...  \n",
       "59          imbalanced  \n",
       "60       undersampling  \n",
       "61       undersampling  \n",
       "62       undersampling  \n",
       "63       undersampling  \n",
       "\n",
       "[64 rows x 7 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_res_alternative"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5b86207399c51f71f4a6f37b6e15eb447a1def4c5b4b45f7ac1063b6bb4c5fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
